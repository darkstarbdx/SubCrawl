# âš ï¸ CURRENTLY THIS TOOL IS FACING SOME INTERNAL PROBLEM, WE ARE WORKIGN TO FIZ IT AS SOON AS POSSIBLE!!!
---
# SubCrawl v1.0ğŸ•·ï¸

Forget about adding API's into tools! **SubCrawl** is your ultimate **ethical hacking** and **bug hunting** sidekick! ğŸ¦¸â€â™‚ï¸ This Python-based tool automates the process of **subdomain enumeration**, **URL fetching**, and **live domain detection**, making reconnaissance faster, easier, and more efficient. With its sleek terminal UI, enhanced animations, and robust functionality, SubCrawl is designed to help you uncover hidden gems on the web. ğŸŒ

---

## ğŸš€ What Does SubCrawl Do?

SubCrawl is a **reconnaissance powerhouse** that helps you:
- **Discover Subdomains**: Uses `subfinder`, `amass`, and `crt.sh` to find all subdomains of a target domain. ğŸ¯
- **Fetch URLs**: Extracts URLs from the Wayback Machine using `waybackurls`. ğŸ•°ï¸
- **Detect Live Domains**: Identifies live domains using `httpx`. ğŸ’»
- **Auto-Install Tools**: Automatically checks for and installs missing dependencies. ğŸ› ï¸

---

## ğŸ‰ Why SubCrawl?

- **Fast and Efficient**: Automates repetitive tasks so you can focus on what matters. âš¡
- **User-Friendly**: Sleek terminal UI with animations and progress bars. ğŸ¨
- **Community-Driven**: Built for hackers, by hackers. ğŸ±â€ğŸ’»

---

## ğŸ› ï¸ Installation

Getting started with SubCrawl is super easy! Follow these steps:

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/darkstarbdx/SubCrawl.git
   cd SubCrawl
   ```

2. **Install Python Dependencies**:
   ```bash
   pip3 install -r requirements.txt
   ```

3. **Run the Tool**:
   ```bash
   python3 main.py
   ```

   SubCrawl will automatically check for and install any missing tools (e.g., `subfinder`, `amass`, `waybackurls`, `httpx`, `jq`, and `curl`). ğŸª„

---

## ğŸ¯ How to Use SubCrawl

Using SubCrawl is as easy as 1-2-3! Hereâ€™s how it works:

1. **Create a Directory**: The tool will prompt you to create a directory to save results. ğŸ“‚
2. **Enter Target Domain**: Provide the target domain (without `http://` or `https://`). ğŸ¯
3. **Let It Work**: SubCrawl will automatically:
   - Enumerate subdomains. ğŸ”
   - Fetch URLs from the Wayback Machine. ğŸŒ
   - Detect live domains. ğŸ’»
4. **View Results**: A detailed dashboard will display the results, including:
   - Total subdomains found. ğŸ•¸ï¸
   - Total URLs fetched. ğŸ•°ï¸
   - Total live domains detected. ğŸ’¡

---

## ğŸ¤ Contributing

Got ideas or suggestions? Want to contribute? Weâ€™d love to have you on board! ğŸš€  
- Open an issue to report bugs or request features. ğŸ›
- Submit a pull request to add new features or improvements. ğŸ› ï¸

---

## ğŸŒ Connect with Me

- **GitHub**: [darkstarbdx](https://github.com/darkstarbdx)
- **Telegram Group**: [Join Here](https://t.me/+mzZ9IrWgXe9jNWNl)

---

## â˜• Support the Project

If you find SubCrawl useful, consider giving it a â­ on GitHub or sharing it with your network. Your support keeps the project alive! ğŸ’™

---

## Ready to Crawl? ğŸ•·ï¸

SubCrawl is here to make your reconnaissance workflow smoother and faster. Give it a try and let us know what you think! ğŸš€
